{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ea074d8-92cb-4827-b594-7c511b8ec9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import SimpleDirectoryReader\n",
    "docs = SimpleDirectoryReader(\"Dataset\").load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1921bee5-1768-4705-a42e-9e0b3913c7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.node_parser.text import SentenceSplitter\n",
    "# Initialize the SentenceSplitter with a specific chunk size\n",
    "text_parser = SentenceSplitter(chunk_size=1024)\n",
    "text_chunks = [] # This will hold all the chunks of text from all documents\n",
    "doc_idxs = [] # This will keep track of the document each chunk came from\n",
    "for doc_idx, doc in enumerate(docs):\n",
    " # Split the current document's text into chunks\n",
    " cur_text_chunks = text_parser.split_text(doc.text)\n",
    " \n",
    " # Extend the list of all text chunks with the chunks from the current document\n",
    " text_chunks.extend(cur_text_chunks)\n",
    " \n",
    " # Extend the document index list with the index of the current document, repeated for each chunk\n",
    " doc_idxs.extend([doc_idx] * len(cur_text_chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b69fd95a-b96f-4ba8-9a3b-f75a81ce7b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.schema import TextNode\n",
    "nodes = [] # This will hold all TextNode objects created from the text chunks\n",
    "# Iterate over each text chunk and its index\n",
    "for idx, text_chunk in enumerate(text_chunks):\n",
    " # Create a TextNode object with the current text chunk\n",
    " node = TextNode(text=text_chunk)\n",
    " \n",
    " # Retrieve the source document using the current index mapped through doc_idxs\n",
    " src_doc = docs[doc_idxs[idx]]\n",
    " \n",
    " # Assign the source document's metadata to the node's metadata attribute\n",
    " node.metadata = src_doc.metadata\n",
    " \n",
    " # Append the newly created node to the list of nodes\n",
    " nodes.append(node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad18fca4-13c5-4c43-9a4f-403593a2ff2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import VectorStoreIndex, StorageContext\n",
    "from llama_index.vector_stores.qdrant import QdrantVectorStore\n",
    "from llama_index.core import Settings\n",
    "from llama_index.core import StorageContext\n",
    "import qdrant_client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5806addf-b451-482b-a8ac-f5ec1c1bd176",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a local Qdrant vector store\n",
    "client = qdrant_client.QdrantClient(path=\"financialnews\")\n",
    "#from qdrant_client import QdrantClient\n",
    "#client = QdrantClient(host=\"localhost\", port=6333)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9ff15866",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store = QdrantVectorStore(client=client, collection_name=\"collection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "36025c28-efd4-454c-b65e-4e0e34d2a385",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: GOOGLE_API_KEY=\"your-api-key\"\n"
     ]
    }
   ],
   "source": [
    "%env GOOGLE_API_KEY = \"your-api-key\"\n",
    "import os\n",
    "GOOGLE_API_KEY = \"your-api-key\" # add your GOOGLE API key here\n",
    "os.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "18cea573-ce46-4e88-bf4e-6c5246138f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.embeddings.fastembed import FastEmbedEmbedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0f0cc33f-9197-4f0d-bdec-5e528f3c741e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5c8fea34f1c497bb94f6ec5855b1265",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initialize the embedding model\n",
    "embed_model = FastEmbedEmbedding(model_name=\"BAAI/bge-small-en-v1.5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b3659f27-622b-4f36-9150-d45b625bf3b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for node in nodes:\n",
    " node_embedding = embed_model.get_text_embedding(\n",
    " node.get_content(metadata_mode=\"all\")\n",
    " )\n",
    " node.embedding = node_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5cb027b4-4726-4f67-ab8c-9a5907dbcb52",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from llama_index.llms.gemini import Gemini\n",
    "Settings.embed_model = embed_model\n",
    "Settings.llm = Gemini(model=\"models/gemini-pro\")\n",
    "Settings.transformations = [SentenceSplitter(chunk_size=1024)]\n",
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eec8c7d3-fec7-40e6-8f54-e5823d03eea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "index = VectorStoreIndex(\n",
    " nodes=nodes,\n",
    " storage_context=storage_context,\n",
    "transformations=Settings.transformations,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c60698e3-92cb-4a32-9dfb-d9badef0c8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import get_response_synthesizer\n",
    "from llama_index.core.query_engine import RetrieverQueryEngine\n",
    "from llama_index.core.retrievers import VectorIndexRetriever\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a81ebc2f-dd34-42aa-b13b-4c9971c731da",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_retriever = VectorIndexRetriever(index=index, similarity_top_k=5)\n",
    "response_synthesizer = get_response_synthesizer()\n",
    "vector_query_engine = RetrieverQueryEngine(\n",
    " retriever=vector_retriever,\n",
    " response_synthesizer=response_synthesizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0deaafe4-a7b5-45c9-b5eb-03729add9484",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.indices.query.query_transform import HyDEQueryTransform\n",
    "from llama_index.core.query_engine import TransformQueryEngine\n",
    "hyde = HyDEQueryTransform(include_original=True)\n",
    "hyde_query_engine = TransformQueryEngine(vector_query_engine, hyde)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "109c8ef1-45cc-4aee-ba0f-4e3e872578de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def queries(query_str):\n",
    " response = hyde_query_engine.query(query_str)\n",
    " return str(response)\n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d0e3cb77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import os\n",
    "gr.close_all()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "931aa38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with gr.Blocks(theme=gr.themes.Glass()) as demo:\n",
    "    gr.Markdown(\n",
    "    \"\"\"\n",
    "    # Welcome to Gemini-Powered News Chatbot!\n",
    "    \"\"\")\n",
    "    chatbot = gr.Chatbot()\n",
    "    msg = gr.Textbox()\n",
    "    clear = gr.ClearButton([msg, chatbot])\n",
    "    def respond(message, chat_history):\n",
    "        bot_message = queries(message)\n",
    "        chat_history.append((message, bot_message))\n",
    "        return \"\", chat_history\n",
    "    msg.submit(respond, [msg, chatbot], [msg, chatbot])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d90ab490-7896-4165-87b1-51db66260f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "demo.launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "26bb37eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing server running on port: 7861\n"
     ]
    }
   ],
   "source": [
    "demo.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e640ce6d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
